{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Download and extract the Kaggle dataset**."
      ],
      "metadata": {
        "id": "V0Z-94JLifoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install kaggle opencv-python scikit-learn numpy scipy joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM3M0vgzY8Jq",
        "outputId": "3036de48-ad9e-485a-a9f6-a040fd5ed440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.12)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from Kaggle\n",
        "!kaggle datasets download -d naveenk903/movies-fight-detection-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReKIqWHEY9sh",
        "outputId": "d99a7458-615a-4f96-c820-489a8d70a72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.14 / client 1.6.12)\n",
            "Dataset URL: https://www.kaggle.com/datasets/naveenk903/movies-fight-detection-dataset\n",
            "License(s): unknown\n",
            "movies-fight-detection-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded dataset\n",
        "!unzip -q movies-fight-detection-dataset.zip"
      ],
      "metadata": {
        "id": "S-FO2vFqZE2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Download and extract the Kaggle dataset**"
      ],
      "metadata": {
        "id": "aik0RK-3imix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from joblib import dump, load"
      ],
      "metadata": {
        "id": "UJf8XehdZKI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Move the dataset to the specified Google Drive folder.**"
      ],
      "metadata": {
        "id": "qrERubfFia7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the dataset to the desired folder on Google Drive\n",
        "source_folder = \"/content/Peliculas\"\n",
        "destination_folder = \"/content/drive/MyDrive/CV_LAB/Lab-10\"\n",
        "shutil.move(source_folder, destination_folder)\n",
        "\n",
        "# Paths to the folders containing the data\n",
        "fights_folder_path = os.path.join(destination_folder, 'fights')\n",
        "nofights_folder_path = os.path.join(destination_folder, 'noFights')\n",
        "\n",
        "# Fraction of data to be used for testing\n",
        "test_size = 0.2"
      ],
      "metadata": {
        "id": "NeEfUZsBZNg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the fights and nofights folders\n",
        "fights_files = os.listdir(fights_folder_path)\n",
        "nofights_files = os.listdir(nofights_folder_path)\n",
        "\n",
        "# Shuffle the files randomly\n",
        "random.shuffle(fights_files)\n",
        "random.shuffle(nofights_files)\n",
        "\n",
        "# Calculate the number of files for testing\n",
        "num_fights_test_files = int(len(fights_files) * test_size)\n",
        "num_nofights_test_files = int(len(nofights_files) * test_size)"
      ],
      "metadata": {
        "id": "8z4AN2VuZQKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Split the dataset into training and testing sets.**"
      ],
      "metadata": {
        "id": "xYK6WpmtiCk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split files into training and testing sets for fights and nofights\n",
        "fights_train_files = fights_files[num_fights_test_files:]\n",
        "fights_test_files = fights_files[:num_fights_test_files]\n",
        "\n",
        "nofights_train_files = nofights_files[num_nofights_test_files:]\n",
        "nofights_test_files = nofights_files[:num_nofights_test_files]\n",
        "\n",
        "# Confirm the split\n",
        "print(f\"Fights Training files: {len(fights_train_files)}\")\n",
        "print(f\"Fights Testing files: {len(fights_test_files)}\")\n",
        "print(f\"NoFights Training files: {len(nofights_train_files)}\")\n",
        "print(f\"NoFights Testing files: {len(nofights_test_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl3zQx_rZSGg",
        "outputId": "0cda09d9-6ea9-4efb-b79e-7bf218a2bf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fights Training files: 80\n",
            "Fights Testing files: 20\n",
            "NoFights Training files: 81\n",
            "NoFights Testing files: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define functions to extract SIFT features and frames from video files.**"
      ],
      "metadata": {
        "id": "gkzugo7Wh_eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract SIFT features from a frame\n",
        "def extract_sift_features(frame):\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(frame, None)\n",
        "    return descriptors"
      ],
      "metadata": {
        "id": "Ud433AOhZTne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and extract features from the dataset.**"
      ],
      "metadata": {
        "id": "VE88EaEJh830"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract frames from a video file\n",
        "def extract_frames_from_video(video_path, interval=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    frames = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % interval == 0:\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            frames.append(gray_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "# Load dataset and extract SIFT features\n",
        "def load_and_extract_features(files, folder_path, interval=30):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for file in files:\n",
        "        video_path = os.path.join(folder_path, file)\n",
        "        frames = extract_frames_from_video(video_path, interval)\n",
        "        for frame in frames:\n",
        "            descriptors = extract_sift_features(frame)\n",
        "            if descriptors is not None:\n",
        "                features.append(descriptors)\n",
        "                if 'fights' in folder_path:\n",
        "                    labels.append(0)  # Label for fight videos\n",
        "                else:\n",
        "                    labels.append(1)  # Label for nofight videos\n",
        "\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "QKC0xUshZV-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from training sets\n",
        "train_features_fights, train_labels_fights = load_and_extract_features(fights_train_files, fights_folder_path, 30)\n",
        "train_features_nofights, train_labels_nofights = load_and_extract_features(nofights_train_files, nofights_folder_path, 30)\n",
        "\n",
        "# Extract features from testing sets\n",
        "test_features_fights, test_labels_fights = load_and_extract_features(fights_test_files, fights_folder_path, 30)\n",
        "test_features_nofights, test_labels_nofights = load_and_extract_features(nofights_test_files, nofights_folder_path, 30)\n",
        "\n",
        "# Combine training features and labels\n",
        "train_features = train_features_fights + train_features_nofights\n",
        "train_labels = train_labels_fights + train_labels_nofights\n",
        "\n",
        "# Combine testing features and labels\n",
        "test_features = test_features_fights + test_features_nofights\n",
        "test_labels = test_labels_fights + test_labels_nofights\n",
        "\n",
        "# Confirm data distribution\n",
        "print(f\"Training labels distribution: {np.bincount(train_labels)}\")\n",
        "print(f\"Testing labels distribution: {np.bincount(test_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZtWOqIiZYjR",
        "outputId": "8f19dbae-cd19-4673-d02b-328696e29bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training labels distribution: [160 162]\n",
            "Testing labels distribution: [40 40]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Cluster the features using KMeans.**"
      ],
      "metadata": {
        "id": "sTKjD5Nmh1nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the feature list for KMeans clustering\n",
        "all_descriptors = np.vstack(train_features)\n",
        "\n",
        "# KMeans clustering to create codebook\n",
        "num_clusters = 100  # Number of clusters for KMeans\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(all_descriptors)\n",
        "dump(kmeans, 'kmeans_codebook.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGjlkMynZbH6",
        "outputId": "dd85c15d-b5d2-4787-e65d-e97de63b9d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['kmeans_codebook.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create histograms of codewords for each video**"
      ],
      "metadata": {
        "id": "Fp5NUfzqhuuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to create histogram of codewords for each video\n",
        "def create_histogram(features, kmeans, num_clusters):\n",
        "    histograms = []\n",
        "    for descriptors in features:\n",
        "        if descriptors is not None:\n",
        "            words = kmeans.predict(descriptors)\n",
        "            histogram, _ = np.histogram(words, bins=np.arange(num_clusters+1), density=True)\n",
        "            histograms.append(histogram)\n",
        "        else:\n",
        "            histograms.append(np.zeros(num_clusters))\n",
        "    return np.array(histograms)\n",
        "\n",
        "# Create histograms for training and testing sets\n",
        "train_histograms = create_histogram(train_features, kmeans, num_clusters)\n",
        "test_histograms = create_histogram(test_features, kmeans, num_clusters)"
      ],
      "metadata": {
        "id": "02UiXbhbZdiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train an SVM classifier.**"
      ],
      "metadata": {
        "id": "7v8mapw0hoMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM classifier\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(train_histograms, train_labels)\n",
        "dump(svm, 'svm_classifier.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUtkZeA7ZfQZ",
        "outputId": "275e0165-c78f-4d6a-dd36-2a4161134d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the classifier and print the performance metrics.**"
      ],
      "metadata": {
        "id": "r1DRE4OmhgAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate\n",
        "labels_pred = svm.predict(test_histograms)\n",
        "accuracy = accuracy_score(test_labels, labels_pred)\n",
        "precision = precision_score(test_labels, labels_pred)\n",
        "recall = recall_score(test_labels, labels_pred)\n",
        "f1 = f1_score(test_labels, labels_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWfHUsOPJZit",
        "outputId": "c63e24a7-467c-4fd8-cfd3-8b4d92f2484e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7\n",
            "Precision: 1.0\n",
            "Recall: 0.4\n",
            "F1 Score: 0.5714285714285715\n"
          ]
        }
      ]
    }
  ]
}